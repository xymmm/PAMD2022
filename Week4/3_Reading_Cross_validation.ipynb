{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cross-validation (CV) is an important step in the whole predictive modelling process.\n",
    "\n",
    "Let's have a look at the basic setup below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The dataset and classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, introduce the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=10,\n",
    "                               n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                               n_classes=2,\n",
    "                               n_clusters_per_class=1,\n",
    "                               weights=(0.7,0.3),\n",
    "                               class_sep=0.99, random_state=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To apply cross-validation, we need a **classifier** as well. Let's use logistic regression for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Applying cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we introduce the classifier into the cross validation process.\n",
    "\n",
    "The classifier is embedded into the whole process, and used on the 10 training sets that are generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [1.   0.96 1.   0.99 0.98 0.99 0.99 1.   0.98 1.  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate a score by cross-validation.\n",
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "# Determines the cross-validation splitting strategy.\n",
    "# Possible inputs for cv are: - `None`, to use the default 5-fold cross validation,\n",
    "# - int, to specify the number of folds\n",
    "\n",
    "print('Accuracy scores: '+str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can change the metrics for the evaluation. Here we use the accuracy to estimate test errors. Let's now add some other metrics as well, e.g., the AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.99666667 1.         1.         0.98571429 0.9952381\n",
      " 1.         1.         0.98571429 1.        ]\n"
     ]
    }
   ],
   "source": [
    "outcomes = cross_val_score(classifier, X, y, cv=10, scoring='roc_auc')\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If **multiple metrics** are required, apply another function \"corss_validate()\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00474572 0.         0.01558685 0.01561785 0.         0.00826049\n",
      " 0.00688982 0.00805593 0.00656676 0.00850964]\n",
      "score_time value: [0.00517964 0.         0.         0.00284147 0.01979542 0.\n",
      " 0.00798917 0.00713611 0.         0.        ]\n",
      "test_roc_auc value: [1.         0.99666667 1.         1.         0.98571429 0.9952381\n",
      " 1.         1.         0.98571429 1.        ]\n",
      "train_roc_auc value: [0.99738354 0.9975654  0.99718994 0.99741873 0.9988971  0.99775313\n",
      " 0.9973542  0.99736594 0.99782939 0.9972134 ]\n",
      "test_accuracy value: [1.   0.96 1.   0.99 0.98 0.99 0.99 1.   0.98 1.  ]\n",
      "train_accuracy value: [0.99       0.99444444 0.99111111 0.99111111 0.99111111 0.99222222\n",
      " 0.99       0.99       0.99333333 0.99111111]\n",
      "test_precision value: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.96666667 1.        ]\n",
      "train_precision value: [0.99621212 0.99626866 0.99622642 0.99622642 0.99622642 0.9962406\n",
      " 0.99621212 0.99621212 1.         0.99621212]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# metrics you want to have computed as a list\n",
    "# It stores each matrix as index for further reference.\n",
    "metrics = ['roc_auc','accuracy','precision']\n",
    "\n",
    "# By default, we should not really care about the training scores.\n",
    "# To show them, we add the extra return_train_score parameter\n",
    "outcomes = cross_validate(classifier, X, y, scoring=metrics, cv=10, return_train_score=True)\n",
    "\n",
    "# We can check the structure of 'outcomes' and print them via keys.\n",
    "# print(outcomes)\n",
    "\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Remember when we talked about training, validation and test sets, we mentioned that the pre-processing (e.g., replacing missing values, transformations, over- and under-sampling, etc.) should be performed on the training and test set **separately** to avoid any bias?\n",
    "\n",
    "**That is, the same transformation, with the same parameters, should be applied to both.**\n",
    "\n",
    "Otherwise, information of the testing set can 'leak' into the training process, while the testing stage needs to be completely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To simplify this, we can set up a pipeline containing the various steps that need to be applied, i.e., transformation and training a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We apply function \"make_pipeline\" from sklearn, to set pipeline of transforms with a final estimator.\n",
    "\n",
    "This function sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be 'transforms', that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.\n",
    "\n",
    "The purpose of the pipeline is to **assemble several steps** that can be cross-validated together **while** setting different parameters.\n",
    "For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00299191 0.         0.01568913 0.         0.0169239  0.\n",
      " 0.         0.00266767 0.         0.01688075]\n",
      "score_time value: [0.         0.         0.         0.         0.         0.\n",
      " 0.01575208 0.         0.         0.00096369]\n",
      "test_accuracy value: [1.   0.96 1.   0.99 0.98 0.99 1.   1.   0.98 1.  ]\n",
      "train_accuracy value: [0.99222222 0.99555556 0.99111111 0.99222222 0.99222222 0.99222222\n",
      " 0.99111111 0.99222222 0.99333333 0.99111111]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Construct a Pipeline from the given estimators.\n",
    "# add another step of standardizing.\n",
    "pipeline = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "outcomes = cross_validate(pipeline, X, y, scoring=metrics, cv=10, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predictions for every sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate cross-validated estimates for each input data point.\n",
    "predictions = cross_val_predict(pipeline, X, y, cv=10)\n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "print(accuracy_score(y, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}