{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cross-validation (CV) is an important step in the whole predictive modelling process.\n",
    "\n",
    "Let's have a look at the basic setup below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The dataset and classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, introduce the dataset and divide it into **training and test set**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=10,\n",
    "                               n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                               n_classes=2,\n",
    "                               n_clusters_per_class=1,\n",
    "                               weights=(0.7,0.3),\n",
    "                               class_sep=0.99, random_state=14)\n",
    "\n",
    "\n",
    "# You already know about training and test splits:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To apply cross-validation, we need a **classifier** as well. Let's use logistic regression for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Applying cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we introduce the classifier into the cross validation process.\n",
    "\n",
    "It really is a process, e.g., for 10-Fold CV, we have a 10-step process.\n",
    "\n",
    "The classifier is embedded into the whole process, and used on the 10 training sets that are generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [0.97857143 1.         0.97857143 0.99285714 0.99285714]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate a score by cross-validation.\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "# Determines the cross-validation splitting strategy.\n",
    "# Possible inputs for cv are: - `None`, to use the default 5-fold cross validation,\n",
    "# - int, to specify the number of folds\n",
    "\n",
    "print('Accuracy scores: '+str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we use the accuracy to estimate test errors. Let's now add some other metrics as well, e.g., the AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.99431818 1.         1.         0.99147727 1.\n",
      " 1.         1.         0.9718173  1.        ]\n"
     ]
    }
   ],
   "source": [
    "outcomes = cross_val_score(classifier, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If **multiple metrics** are required, apply another function \"corss_validate()\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "score_time value: [0.         0.01559424 0.         0.         0.         0.\n",
      " 0.0156486  0.         0.01559424 0.        ]\n",
      "test_roc_auc value: [1.         0.99431818 1.         1.         0.99147727 1.\n",
      " 1.         1.         0.9718173  1.        ]\n",
      "train_roc_auc value: [0.99679871 0.99722555 0.99684614 0.99691728 0.9973204  0.9969616\n",
      " 0.99691431 0.99671333 0.99949163 0.99673697]\n",
      "test_accuracy value: [0.95714286 0.98571429 1.         1.         0.97142857 1.\n",
      " 1.         0.98571429 0.98571429 1.        ]\n",
      "train_accuracy value: [0.99206349 0.99206349 0.98888889 0.98888889 0.99365079 0.98888889\n",
      " 0.98888889 0.99047619 0.99047619 0.98888889]\n",
      "test_precision value: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "train_precision value: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# metrics you want to have computed as a list\n",
    "# It stores each matrix as index for further reference.\n",
    "metrics = ['roc_auc','accuracy','precision']\n",
    "\n",
    "# By default, we should not really care about the training scores.\n",
    "# To show them, we add the extra return_train_score parameter\n",
    "outcomes = cross_validate(classifier, X_train, y_train, scoring=metrics, cv=10, return_train_score=True)\n",
    "\n",
    "# We can check the structure of 'outcomes' and print them via keys.\n",
    "# print(outcomes)\n",
    "\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, the outcome is a dictionary with the different metrics per fold for both the training and test set.\n",
    "\n",
    "Note that, since we have set aside a separate test set, this is our validation set in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Remember when we talked about training, validation and test sets, we mentioned that the pre-processing (e.g., replacing missing values, transformations, over- and under-sampling, etc.) should be performed on the training and test set **separately** to avoid any bias?\n",
    "\n",
    "**That is, the same transformation, with the same parameters, should be applied to both.**\n",
    "\n",
    "Otherwise, information of the testing set can 'leak' into the training process, while the testing stage needs to be completely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To simplify this, we can set up a pipeline containing the various steps that need to be applied, i.e., transformation and training a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We apply function \"make_pipeline\" from sklearn, to set pipeline of transforms with a final estimator.\n",
    "\n",
    "This function sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be 'transforms', that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.\n",
    "\n",
    "The purpose of the pipeline is to **assemble several steps** that can be cross-validated together **while** setting different parameters.\n",
    "For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.         0.         0.         0.01561165 0.         0.\n",
      " 0.         0.         0.01562285 0.        ]\n",
      "score_time value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test_accuracy value: [0.97142857 0.98571429 1.         1.         0.97142857 0.98571429\n",
      " 1.         0.98571429 0.98571429 1.        ]\n",
      "train_accuracy value: [0.99206349 0.99206349 0.99047619 0.99047619 0.99206349 0.99047619\n",
      " 0.98888889 0.99047619 0.99047619 0.98888889]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Construct a Pipeline from the given estimators.\n",
    "pipeline = make_pipeline(StandardScaler(), classifier)\n",
    "outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=10, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predictions for every sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you want to obtain the predictions for every sample from when it was in the test set (in 10-fold CV, every sample is used exactly once), the following code can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate cross-validated estimates for each input data point.\n",
    "predictions = cross_val_predict(pipeline, X_train, y_train, cv=10)\n",
    "\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Typically, we will use cross-validation to see what classifier, or what parameters, are working best over our training/validation sets.\n",
    "\n",
    "Then, finally, we use them on our test set for our final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Adding sampling strategy to pipeline (reading only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since our data is imbalanced, we might want to preserve this imbalance in every fold. To do so, we can use the stratified CV procedure as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "score_time value: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test_accuracy value: [0.97142857 0.98571429 0.98571429 1.         0.98571429 1.\n",
      " 0.97142857 1.         1.         0.98571429]\n",
      "train_accuracy value: [0.99365079 0.99047619 0.99047619 0.99047619 0.99206349 0.98888889\n",
      " 0.99206349 0.98888889 0.98888889 0.99047619]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle= True, random_state=42)\n",
    "outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=stratified_kfold, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}