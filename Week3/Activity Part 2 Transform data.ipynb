{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first reload the dataset we obtained after pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Occupation  Marital_Status  Purchase_Sum  annual_income  \\\n",
      "0          10               0         38891    42521.93013   \n",
      "1          16               0         37417    59199.36954   \n",
      "2          15               0         49947    40056.02938   \n",
      "3           7               1         66607    79474.66782   \n",
      "4          20               1         50684    85567.55715   \n",
      "\n",
      "   number_of_children  proximity_town    sum  Age_18-25  Age_26-35  Age_36-45  \\\n",
      "0                   2        2.677101  38891          0          0          0   \n",
      "1                   0        3.589760  37417          0          0          0   \n",
      "2                   1        3.944390  49947          0          1          0   \n",
      "3                   0        2.702605  66607          0          0          0   \n",
      "4                   1        2.841509  50684          0          1          0   \n",
      "\n",
      "   Age_46-50  Age_51-55  Age_55+  Gender_M  City_Category_B  City_Category_C  \\\n",
      "0          0          0        0         0                0                0   \n",
      "1          0          0        1         1                0                1   \n",
      "2          0          0        0         1                0                0   \n",
      "3          1          0        0         1                1                0   \n",
      "4          0          0        0         1                0                0   \n",
      "\n",
      "   Stay_In_Current_City_Years_1  Stay_In_Current_City_Years_2  \\\n",
      "0                             0                             1   \n",
      "1                             0                             0   \n",
      "2                             0                             0   \n",
      "3                             0                             1   \n",
      "4                             1                             0   \n",
      "\n",
      "   Stay_In_Current_City_Years_3  Stay_In_Current_City_Years_4+  \n",
      "0                             0                              0  \n",
      "1                             0                              1  \n",
      "2                             1                              0  \n",
      "3                             0                              0  \n",
      "4                             0                              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv('CS_pre_processed_data.csv', index_col=0)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that there are missing values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation has \t\t\t 0  missing values\n",
      "Marital_Status has \t\t\t 0  missing values\n",
      "Purchase_Sum has \t\t\t 0  missing values\n",
      "annual_income has \t\t\t 0  missing values\n",
      "number_of_children has \t\t\t 0  missing values\n",
      "proximity_town has \t\t\t 158  missing values\n",
      "sum has \t\t\t 0  missing values\n",
      "Age_18-25 has \t\t\t 0  missing values\n",
      "Age_26-35 has \t\t\t 0  missing values\n",
      "Age_36-45 has \t\t\t 0  missing values\n",
      "Age_46-50 has \t\t\t 0  missing values\n",
      "Age_51-55 has \t\t\t 0  missing values\n",
      "Age_55+ has \t\t\t 0  missing values\n",
      "Gender_M has \t\t\t 0  missing values\n",
      "City_Category_B has \t\t\t 0  missing values\n",
      "City_Category_C has \t\t\t 0  missing values\n",
      "Stay_In_Current_City_Years_1 has \t\t\t 0  missing values\n",
      "Stay_In_Current_City_Years_2 has \t\t\t 0  missing values\n",
      "Stay_In_Current_City_Years_3 has \t\t\t 0  missing values\n",
      "Stay_In_Current_City_Years_4+ has \t\t\t 0  missing values\n"
     ]
    }
   ],
   "source": [
    "for var in dataset.columns:\n",
    "    print(var, 'has \\t\\t\\t', dataset[var].isna().sum(), ' missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that replaces missing values with the mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "replace_missing_values",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_missing_values(dataset, variable):\n",
    "    transformed_data = dataset.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    # We first calculate the mean\n",
    "    mean = np.nanmean(transformed_data[variable])\n",
    "    \n",
    "    # Next, we fill in the NAs with the value\n",
    "    transformed_data[variable] = transformed_data[variable].fillna(mean)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer will be verified below (no need for you to do anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "replace_missing_values",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from pandas.testing import assert_frame_equal\n",
    "transformed_data = dataset.copy()  \n",
    "mean = np.nanmean(transformed_data['proximity_town'])\n",
    "transformed_data['proximity_town'] = transformed_data['proximity_town'].fillna(mean)\n",
    "assert transformed_data.equals(replace_missing_values(dataset, 'proximity_town'))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Occupation  Marital_Status  Purchase_Sum  annual_income  \\\n",
      "0          10               0         38891    42521.93013   \n",
      "1          16               0         37417    59199.36954   \n",
      "2          15               0         49947    40056.02938   \n",
      "3           7               1         66607    79474.66782   \n",
      "4          20               1         50684    85567.55715   \n",
      "\n",
      "   number_of_children  proximity_town    sum  Age_18-25  Age_26-35  Age_36-45  \\\n",
      "0                   2        2.677101  38891          0          0          0   \n",
      "1                   0        3.589760  37417          0          0          0   \n",
      "2                   1        3.944390  49947          0          1          0   \n",
      "3                   0        2.702605  66607          0          0          0   \n",
      "4                   1        2.841509  50684          0          1          0   \n",
      "\n",
      "   Age_46-50  Age_51-55  Age_55+  Gender_M  City_Category_B  City_Category_C  \\\n",
      "0          0          0        0         0                0                0   \n",
      "1          0          0        1         1                0                1   \n",
      "2          0          0        0         1                0                0   \n",
      "3          1          0        0         1                1                0   \n",
      "4          0          0        0         1                0                0   \n",
      "\n",
      "   Stay_In_Current_City_Years_1  Stay_In_Current_City_Years_2  \\\n",
      "0                             0                             1   \n",
      "1                             0                             0   \n",
      "2                             0                             0   \n",
      "3                             0                             1   \n",
      "4                             1                             0   \n",
      "\n",
      "   Stay_In_Current_City_Years_3  Stay_In_Current_City_Years_4+  \n",
      "0                             0                              0  \n",
      "1                             0                              1  \n",
      "2                             1                              0  \n",
      "3                             0                              0  \n",
      "4                             0                              0  \n"
     ]
    }
   ],
   "source": [
    "print(transformed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that stores whether a variable is an outlier or not, in a separate column called 'outlier':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "mark_outliers",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mark_outliers(dataset, n_neighbours, contam):\n",
    "    marked_outliers = dataset.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    # First we import the appropriate code\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "    \n",
    "    # As before, we apply LOF and add a new column to the dataset\n",
    "    loc= LocalOutlierFactor(n_neighbors = n_neighbours, contamination = contam)\n",
    "    outliers_loc = loc.fit_predict(marked_outliers)\n",
    "    marked_outliers['outlier'] = pd.DataFrame(outliers_loc)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return marked_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer will be verified below (no need for you to do anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "mark_outliers",
     "locked": true,
     "points": "8",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from pandas.testing import assert_frame_equal\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "n_neighbours = 20\n",
    "contam = 0.1\n",
    "\n",
    "marked_outliers = transformed_data.copy()   \n",
    "loc= LocalOutlierFactor(n_neighbors = n_neighbours, contamination = contam)\n",
    "outliers_loc = loc.fit_predict(marked_outliers)\n",
    "marked_outliers['outlier'] = pd.DataFrame(outliers_loc)\n",
    "\n",
    "assert marked_outliers.equals(mark_outliers(transformed_data, n_neighbours, contam))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    4881\n",
      "-1     543\n",
      "Name: outlier, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(marked_outliers['outlier'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final step, we are going to standard normalise the numeric variables. Note that only particular variables need this treatment, as the binary ones are already within range. Write a function to transform the other variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7489ebdad77835a6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def standardise_variable(dataset, variables):\n",
    "    normalised_data = dataset.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    # We import the appropriate code\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # We apply the standard scaler to values of the variables that are inputted\n",
    "    ss = StandardScaler()\n",
    "    norm_data = ss.fit_transform(normalised_data[variables].values)\n",
    "    normalised_data[to_normalise] = norm_data\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return normalised_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer will be verified below (no need for you to do anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "standardise_variable",
     "locked": true,
     "points": "6",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from pandas.testing import assert_frame_equal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalised_data = marked_outliers.copy()\n",
    "\n",
    "to_normalise = ['annual_income', 'proximity_town', 'Occupation', 'Purchase_Sum', 'number_of_children']    \n",
    "ss = StandardScaler()\n",
    "norm_data = ss.fit_transform(normalised_data[to_normalise].values)\n",
    "normalised_data[to_normalise] = norm_data\n",
    "\n",
    "assert normalised_data.equals(standardise_variable(marked_outliers, to_normalise))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data now looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Occupation  Marital_Status  Purchase_Sum  annual_income  \\\n",
      "0    0.288734               0     -0.452944      -0.434067   \n",
      "1    1.233680               0     -0.467259      -0.275620   \n",
      "2    1.076189               0     -0.345577      -0.457494   \n",
      "3   -0.183740               1     -0.183788      -0.082992   \n",
      "4    1.863644               1     -0.338420      -0.025106   \n",
      "\n",
      "   number_of_children  proximity_town    sum  Age_18-25  Age_26-35  Age_36-45  \\\n",
      "0            1.050259       -0.797397  38891          0          0          0   \n",
      "1           -0.982428       -0.750248  37417          0          0          0   \n",
      "2            0.033916       -0.731928  49947          0          1          0   \n",
      "3           -0.982428       -0.796079  66607          0          0          0   \n",
      "4            0.033916       -0.788903  50684          0          1          0   \n",
      "\n",
      "   ...  Age_51-55  Age_55+  Gender_M  City_Category_B  City_Category_C  \\\n",
      "0  ...          0        0         0                0                0   \n",
      "1  ...          0        1         1                0                1   \n",
      "2  ...          0        0         1                0                0   \n",
      "3  ...          0        0         1                1                0   \n",
      "4  ...          0        0         1                0                0   \n",
      "\n",
      "   Stay_In_Current_City_Years_1  Stay_In_Current_City_Years_2  \\\n",
      "0                             0                             1   \n",
      "1                             0                             0   \n",
      "2                             0                             0   \n",
      "3                             0                             1   \n",
      "4                             1                             0   \n",
      "\n",
      "   Stay_In_Current_City_Years_3  Stay_In_Current_City_Years_4+  outlier  \n",
      "0                             0                              0        1  \n",
      "1                             0                              1        1  \n",
      "2                             1                              0        1  \n",
      "3                             0                              0        1  \n",
      "4                             0                              0        1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(normalised_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can save your final output for Part 3: Modelling, which is the final step in the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_data.to_csv('CS_transformed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
