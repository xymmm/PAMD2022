{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load our modules and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv('CS_Purchase_data.csv', index_col=0)\n",
    "print(dataset.head())\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['Product_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Marital_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['User_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Product_Category_3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a good look at the different variables we have. There are two IDs: one for the users, one for the products. Those two entities each have properties, i.e. users have an age, occupation, annual income etc., and products have categories. Furthermore, for each transaction the purchase amount is given (variable 'Purchase')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the exercise requires us to predict the purchase amount of a particular customer, the dataset needs to be transformed accordingly. In this part, you will aggregate the purchase data per user and remove the columns we no longer need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to remove the unnecessary columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, list the ones (i.e. copy their exact column name) you think should be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fill_in_columns",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fill_in_columns():\n",
    "    to_remove = []\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    to_remove = ['Product_Category_1','Product_Category_2', 'Product_Category_3', 'Product_ID']\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "remove_columns",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_columns(dataset, to_remove):\n",
    "    purchase_data = dataset.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    purchase_data = dataset.drop(to_remove, axis=1)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return purchase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = dataset.copy()\n",
    "purchase_data = remove_columns(data_copy,fill_in_columns())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, aggregate the observations based on the user ID and make a new column 'Purchase_Sum' which contains the sum of all purchases of a particular user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "aggregate_observations",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_observations(dataset):\n",
    "    purchase_data = dataset.copy()\n",
    "    \n",
    "    purchase_data = purchase_data.groupby( ['User_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']).sum()\n",
    "    purchase_data = purchase_data.add_suffix('_Sum').reset_index()\n",
    "    \n",
    "    return purchase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "purchase_data_copy = data_copy.copy()\n",
    "purchase_data_copy = aggregate_observations(purchase_data_copy)\n",
    "print(purchase_data_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from pandas.testing import assert_frame_equal\n",
    "result = purchase_data.groupby( ['User_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']).sum()\n",
    "result = result.add_suffix('_Sum').reset_index()\n",
    "assert result.equals(aggregate_observations(purchase_data))\n",
    "purchase_data = result\n",
    "### END HIDDEN TESTS\n",
    "print(purchase_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add the extra customer data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.read_csv('CS_Customer_data.csv')\n",
    "print(customer_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that merges the two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65f4f778eb31a67f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def merge_datasets(purchase_data, customer_data):\n",
    "    final_data = purchase_data.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    final_data=pd.merge(purchase_data, customer_data, on=\"User_ID\", how='left')\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = merge_datasets(purchase_data, customer_data)\n",
    "for var in final_data.columns:\n",
    "    if var in final_data.select_dtypes(include=['float64', 'float32', 'int64', 'int32']):\n",
    "        plt.hist(final_data[var].fillna(0))\n",
    "    else:\n",
    "        plt.bar(x = final_data[var].unique(), height = final_data[var].value_counts())\n",
    "    plt.title(var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following problems could be spotted:\n",
    "- User_ID : is ID, not needed anymore\n",
    "- Marital status: should not be numeric\n",
    "- Occupation: should not be numeric\n",
    "\n",
    "However, we are going to do linear regression. Hence, we want to transform the categorical attributes into numeric ones, including:\n",
    "- Gender\n",
    "- Age\n",
    "- City category\n",
    "- Stay in current city years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_id_data = final_data.drop(['User_ID'], axis=1)\n",
    "print(fixed_id_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function to fix the categorical variables using dummy encoding. The new variables should contain the variable name as prefix (see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "transform_categorical_variables",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def transform_categorical_variables(fixed_id_data, to_transform):\n",
    "    transformed_data = fixed_id_data.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION    \n",
    "    # We loop all the variables we want to transform, and to so by introducing dummy variables\n",
    "    for var in to_transform:\n",
    "        transformed_data = pd.concat([transformed_data.drop(var, axis=1), pd.get_dummies(transformed_data[var].values, prefix=var, drop_first=True)], axis=1)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That concludes Part 1: Pre-processing. You can save your progress for the next stage in our process, Part 2: Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_transform = ['Age', 'Gender', 'City_Category', 'Stay_In_Current_City_Years']\n",
    "transformed_data = transform_categorical_variables(fixed_id_data, to_transform)\n",
    "print(transformed_data.head())\n",
    "transformed_data.to_csv('CS_pre_processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
