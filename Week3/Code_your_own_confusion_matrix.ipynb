{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding your own confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1e9e6a6af3b5dd6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We are now going to calculate the confusion matrix for a binary classification and the various metrics that are based on it. \n",
    "\n",
    "So, let's start by building the data we need, i.e., three datasets (abbreviated to 'dat') with a binary dependent variable for which we will build a separate classification and one benchmarking set that contains the 'real' observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35e8838b4f779ee2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve as roc\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Use with high-resolution screens\n",
    "#plt.rcParams[\"figure.dpi\"] = 144\n",
    "\n",
    "\n",
    "dat1 = make_classification(n_samples=100, \n",
    "                    n_features=3, \n",
    "                    n_informative=3, \n",
    "                    n_redundant=0, \n",
    "                    n_repeated=0, \n",
    "                    n_classes=2, \n",
    "                    n_clusters_per_class=2, random_state=8)\n",
    "dat2 = make_classification(n_samples=100, \n",
    "                    n_features=3, \n",
    "                    n_informative=3, \n",
    "                    n_redundant=0, \n",
    "                    n_repeated=0, \n",
    "                    n_classes=2, \n",
    "                    n_clusters_per_class=2, random_state=9)\n",
    "dat3 = make_classification(n_samples=100, \n",
    "                    n_features=3, \n",
    "                    n_informative=3, \n",
    "                    n_redundant=0, \n",
    "                    n_repeated=0, \n",
    "                    n_classes=2, \n",
    "                    n_clusters_per_class=2, random_state=6)\n",
    "\n",
    "actuals = [dat1[1],dat2[1],dat3[1]]\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "log_reg.fit(dat1[0],dat1[1])\n",
    "outputD1 = log_reg.predict(dat1[0])\n",
    "log_reg.fit(dat2[0],dat2[1])\n",
    "outputD2 = log_reg.predict(dat2[0])\n",
    "log_reg.fit(dat3[0],dat3[1])\n",
    "outputD3 = log_reg.predict(dat3[0])\n",
    "predictions = [outputD1,outputD2,outputD3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4460b18f1010644",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class labels\n",
      "[array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]), array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])]\n",
      "The predictions (discrete)\n",
      "[array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1]), array([0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]), array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(\"The class labels\")\n",
    "print(actuals)\n",
    "print(\"The predictions (discrete)\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-166aa1827eb3df82",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Then, we calculate the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cm(predicted, actual):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0    \n",
    "      \n",
    "    # Go over all predicted values\n",
    "    for i in range(0,len(predicted)):\n",
    "        # Check if positive or not\n",
    "        if predicted[i] == 1:\n",
    "            # If positive, check whether true, or false positive\n",
    "            if predicted[i] == actual[i]:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FP+=1\n",
    "        else:\n",
    "            # If negative, check whether true, or false negative\n",
    "            if predicted[i] == actual[i]:\n",
    "                TN+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "    \n",
    "    return TP,FP,FN,TN   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e50b783cc22b150",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11c5d8e8f83adaf3",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0\n",
      "\tT\tF\n",
      "T\t37\t18\n",
      "F\t14\t31\n",
      "Dataset 1\n",
      "\tT\tF\n",
      "T\t42\t6\n",
      "F\t8\t44\n",
      "Dataset 2\n",
      "\tT\tF\n",
      "T\t45\t5\n",
      "F\t4\t46\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print('Dataset '+str(i))\n",
    "    TP,FP,FN,TN = calculate_cm(predictions[i], actuals[i])\n",
    "    print('\\tT\\tF')\n",
    "    print('T\\t'+str(TP)+'\\t'+str(FP))\n",
    "    print('F\\t'+str(FN)+'\\t'+str(TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5dc30c9fb222bc6b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now, calculate the other metrics yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(TP,FP,FN,TN):\n",
    "    acc = 0\n",
    "    \n",
    "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    return acc\n",
    "    \n",
    "def calculate_recall(TP,FP,FN,TN):\n",
    "    recall = 0\n",
    "    \n",
    "    recall = (TP)/(TP+FN)  \n",
    "    \n",
    "    return recall\n",
    "    \n",
    "def calculate_specificity(TP,FP,FN,TN):   \n",
    "    spec = 0\n",
    "\n",
    "    spec = (TN)/(TN+FP) \n",
    "    \n",
    "    return spec \n",
    "\n",
    "def calculate_precision(TP,FP,FN,TN):\n",
    "    prec = 0\n",
    "    \n",
    "    prec = (TP)/(TP+FP) \n",
    "    \n",
    "    return prec \n",
    "\n",
    "def calculate_fallout(TP,FP,FN,TN):  \n",
    "    fall = 0\n",
    "    \n",
    "    fall = (FP)/(FP+TN)\n",
    "    \n",
    "    return fall  \n",
    "\n",
    "def calculate_fscore(TP,FP,FN,TN):\n",
    "    f = 0\n",
    "    \n",
    "    f = 2/((1/calculate_recall(TP,FP,FN,TN))+(1/calculate_precision(TP,FP,FN,TN))) \n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd034de493cf4d2f",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Finally, verify your answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca751aaa1441a062",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "Dataset 0\n",
      "Accuracy 0.68\n",
      "Recall 0.7254901960784313\n",
      "Precision 0.6727272727272727\n",
      "Specificity 0.6326530612244898\n",
      "Fall-out 0.3673469387755102\n",
      "F1-score 0.6981132075471698\n",
      "\n",
      "------------------\n",
      "Dataset 1\n",
      "Accuracy 0.86\n",
      "Recall 0.84\n",
      "Precision 0.875\n",
      "Specificity 0.88\n",
      "Fall-out 0.12\n",
      "F1-score 0.8571428571428572\n",
      "\n",
      "------------------\n",
      "Dataset 2\n",
      "Accuracy 0.91\n",
      "Recall 0.9183673469387755\n",
      "Precision 0.9\n",
      "Specificity 0.9019607843137255\n",
      "Fall-out 0.09803921568627451\n",
      "F1-score 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print('\\n------------------\\nDataset '+str(i))\n",
    "    TP,FP,FN,TN = calculate_cm(predictions[i], actuals[i])\n",
    "    \n",
    "    print('Accuracy '+str(calculate_accuracy(TP,FP,FN,TN)))\n",
    "    print('Recall '+str(calculate_recall(TP,FP,FN,TN)))\n",
    "    print('Precision '+str(calculate_precision(TP,FP,FN,TN)))\n",
    "    print('Specificity '+str(calculate_specificity(TP,FP,FN,TN)))\n",
    "    print('Fall-out '+str(calculate_fallout(TP,FP,FN,TN)))\n",
    "    print('F1-score '+str(calculate_fscore(TP,FP,FN,TN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-876dff8a8b677de4",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15254237288135594\n",
      "0.17475728155339806\n",
      "0.5454545454545454\n",
      "0.0\n",
      "1.0\n",
      "0.2647058823529412\n"
     ]
    }
   ],
   "source": [
    "TP = 18\n",
    "FP = 15\n",
    "TN = 85\n",
    "FN = 0\n",
    "print(calculate_accuracy(TP,FP,TN,FN))\n",
    "print(calculate_recall(TP,FP,TN,FN))\n",
    "print(calculate_precision(TP,FP,TN,FN))\n",
    "print(calculate_specificity(TP,FP,TN,FN))\n",
    "print(calculate_fallout(TP,FP,TN,FN))\n",
    "print(calculate_fscore(TP,FP,TN,FN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
