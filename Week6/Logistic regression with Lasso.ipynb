{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mineral-repair",
   "metadata": {},
   "source": [
    "# Penalized (Lasso) logistic model\n",
    "\n",
    "Let's illustrate the penalized classification using the Wine data set:\n",
    "\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset\n",
    "\n",
    "This is a multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "dataset = datasets.load_wine()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaled predictors\n",
    "x_train_scaled = StandardScaler().fit_transform(x_train)\n",
    "x_test_scaled = StandardScaler().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data1 = pd.DataFrame(data= np.c_[dataset['data'], dataset['target']],\n",
    "                     columns= dataset['feature_names'] + ['target'])                     \n",
    "\n",
    "data1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-nelson",
   "metadata": {},
   "source": [
    "Run k-fold cross validation to tune the penalization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso_logistic_model = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='liblinear')\n",
    "\n",
    "grid = dict() \n",
    "grid['C'] = arange(0.0001, 1, 0.01)\n",
    "\n",
    "search = GridSearchCV(lasso_logistic_model, grid, scoring='accuracy', cv=5, refit=True)\n",
    "results = search.fit(x_train_scaled, y_train)\n",
    "\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-evaluation",
   "metadata": {},
   "source": [
    "Let's visualize the coefficients of the lasso-logistic model and compare with those of the standard (non-penalized) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficients of the lasso-logistic model\n",
    "lasso_model = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    C = 0.4901).fit(x_train_scaled,y_train)\n",
    "print(\"Coefficients of the lasso logistic model: \\n\\n\",lasso_model.coef_)\n",
    "\n",
    "# Coeficients of the traditional logistic model\n",
    "logistic_model = LogisticRegression(\n",
    "    penalty='none').fit(x_train_scaled,y_train)\n",
    "print(\"\\n\\n Coefficients of the traditional logistic model: \\n\\n\",logistic_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-count",
   "metadata": {},
   "source": [
    "Let's compute the predictions for the test set with the lasso-logistic and with the standard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with the lasso-logistic model\n",
    "predictions_tuned_model = search.predict(x_test_scaled)\n",
    "print(predictions_tuned_model)\n",
    "\n",
    "# Predictions with the standard logistic model\n",
    "logictic_model = LogisticRegression(solver='liblinear').fit(x_train_scaled,y_train)\n",
    "predictions_non_tuned_model = logictic_model.predict(x_test_scaled)\n",
    "print(predictions_non_tuned_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-rotation",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "\n",
    "\n",
    "print(\"Confusion matrix for the lasso-logistic model: \\n\"+str(cm(y_test,predictions_tuned_model)))\n",
    "\n",
    "print(\"Confusion matrix for the traditional logistic model: \\n\"+str(cm(y_test,predictions_non_tuned_model)))\n",
    "\n",
    "print(\"Accuracy lasso model: \"+str(accuracy(y_test,predictions_tuned_model)))\n",
    "\n",
    "print(\"Accuracy traditional model: \"+str(accuracy(y_test,predictions_non_tuned_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-cement",
   "metadata": {},
   "source": [
    "# Addressing imbalance while tuning a classification model \n",
    "\n",
    "In this example will see how to include the sampling tehnique SMOTE within the modelling cycle for tuning the lasso-logistic model. For that, we will use the breast cancer data set to see if we are able to identify malignant labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load data set\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = tts(X,y,test_size=0.3,stratify=y,random_state=11)\n",
    "\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with SMOTE in it\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=11)],\n",
    "                                ['scaler', StandardScaler()],\n",
    "                                ['classifier', LogisticRegression(random_state=11,\n",
    "                                                                  penalty='l1',\n",
    "                                                                  solver='liblinear')]])\n",
    "\n",
    "# Grid for the shrinkage intensuity\n",
    "grid = dict() \n",
    "grid['classifier__C'] = arange(0.0001, 2, 0.01)\n",
    "\n",
    "# Setup stratified cross-validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                   shuffle=True,\n",
    "                                   random_state=11)\n",
    "\n",
    "# Run cross-validation using the AUC as scoring metric\n",
    "search = GridSearchCV(pipeline, grid, scoring='roc_auc', cv=stratified_kfold, refit=True)\n",
    "results = search.fit(X_train, y_train)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = search.best_score_\n",
    "test_score = search.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
