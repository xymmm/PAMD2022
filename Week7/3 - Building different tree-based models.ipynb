{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building different tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now built two basic decision trees.\n",
    "\n",
    "In the lecture, we talked about the disadvantages of decision trees and how they are sometimes not very accurate in their predictions. There are a couple of ways of overcoming that.\n",
    "\n",
    "Inaccuracy through overfitting can be reduced by pruning. Another way of improving accuracy is by using multiple trees at once - an ensemble of them. Ensemble learning is a whole area in machine learning which aims to improve the accuracy of a model by combining multiple of them.\n",
    "\n",
    "In this activity we will build a random forest and a boosting model for the churn dataset. \n",
    "Let's first import the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our churn dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### added line to ensure plots are showing\n",
    "%matplotlib inline\n",
    "#####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('churn_ibm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know the pre-processing steps from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "X = df.drop(['Churn','customerID'],axis=1)\n",
    "\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == object:\n",
    "        X = pd.concat([X,pd.get_dummies(X[column], prefix=column, drop_first=True)],axis=1).drop([column],axis=1)\n",
    "        \n",
    "y = pd.get_dummies(y, prefix='churn', drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember random forests: they are ensembles of decision trees that are forced to use randomized predictors in their splits. They then all vote together on an outcome.\n",
    "\n",
    "Scikit learn allows us to construct a random forest quite easily. Have a look at the documentation first here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7800947867298578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20) \n",
    "# pick your number of trees for n_estimators: as usual, more trees can be more accurate but \n",
    "# are computationally more expensive. There is no fixed \"perfect\" number that you can use, it'll depend on\n",
    "# your data and your computer's capacities\n",
    "\n",
    "# you'll also be able to specify your splitting citerion, maximum depth, minimum leaf sample number etc. as usual\n",
    "\n",
    "# also note: the attribute \"bootstrap\" is default to \"true\". We talked about bootstrapping in the lecture\n",
    "# as another way of introducing randomness by sampling with replacement from the data and generating \n",
    "# multiple training set that way\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Some algorithms need a transformed version of the dependent variable\n",
    "# To this purpose, the data is reshaped using ravel()\n",
    "rf.fit(X_train,y_train.values.ravel())\n",
    "prediction = rf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      churn_Yes\n",
       "0             0\n",
       "1             0\n",
       "2             1\n",
       "3             0\n",
       "4             1\n",
       "...         ...\n",
       "7027          0\n",
       "7028          0\n",
       "7029          0\n",
       "7030          1\n",
       "7031          0\n",
       "\n",
       "[7032 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ravel is a pretty handy function from numpy: \n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n",
    "# It returns our Y as a 1-dimensional array of values\n",
    "\n",
    "# Check this out to see what it does:\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot more to play around with in the RandomForestClassifier function. You can print the instance of ```RandomForestClassifier``` to learn about the default settings used.\n",
    "\n",
    "This can be very important when reporting your results. For example, we've already said that bootstrapping is defaulted to TRUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 20, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the parameters. Let's build a larger forest using more trees using parameter ```n_estimators```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790521327014218\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=100)\n",
    "rf2.fit(X_train,y_train.values.ravel())\n",
    "prediction = rf2.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, our accuracy did improve a little from 0.7801 to 0.7905."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what is contained in the prediction array, it's all binary as our to-be-predicted class (churn) is measured as a yes/no question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Prediction:',prediction[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also output the probabilities for every class, as follows, and use it for AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.99 0.01]\n",
      " [0.99 0.01]\n",
      " [0.68 0.32]\n",
      " [0.74 0.26]\n",
      " [0.84 0.16]\n",
      " [0.29 0.71]\n",
      " [1.   0.  ]\n",
      " [0.59 0.41]\n",
      " [0.29 0.71]\n",
      " [0.32 0.68]]\n",
      "AUC: 0.8287332790746316\n"
     ]
    }
   ],
   "source": [
    "prediction_prob = rf2.predict_proba(X_test)\n",
    "print('Prediction:',prediction_prob[0:10])\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our AUC from earlier? It was 0.7174 for the classification tree that we built in the first exercise.\n",
    "\n",
    "We can see that our RF improved that quite a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is a way of learning from past behavior. We are building a sequence of small trees, each of which will use the errors that the previous one did to improve its own performance.\n",
    "\n",
    "sklearn allows us to implement two versions of the boosting method: AdaBoost and Gradient Boosting. Let's implement AdaBoost as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7943127962085308\n",
      "AUC: 0.8448335637054754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "# As usual, I would recommend checking out the documentation for this method. You'll find out which parameters\n",
    "# are set or can be chosen by you.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "# You can give AdaBoost a tree to start with, or you can just let it do that on its own.\n",
    "# The method learns by looking at past incorrect classifications and then weighting them more heavily in its\n",
    "# next iteration.\n",
    "\n",
    "ada.fit(X_train,y_train.values.ravel())\n",
    "prediction = ada.predict(X_test)\n",
    "prediction_prob = ada.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test,prediction))\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that accuracy and AUC - looks like we're improving just a little from our previous RF (Accuracy: 0.7905; AUC: 0.8287).\n",
    "\n",
    "Apparently, AdaBoost is currently using 50 trees which we can find out by looking at its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "print(ada.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's increase that number of trees to check whether we can improve our performance even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7943127962085308\n",
      "AUC: 0.8448335637054754\n"
     ]
    }
   ],
   "source": [
    "ada2 = AdaBoostClassifier(n_estimators=100)\n",
    "ada2.fit(X_train,y_train.values.ravel())\n",
    "prediction = ada2.predict(X_test)\n",
    "prediction_prob = ada.predict_proba(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test,prediction))\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither accuracy, nor AUC are improved drastically, but AdaBoost performs better than the Random Forest we built.\n",
    "\n",
    "What does that tell us about our data? There might be observations which are particularly difficult to pinpoint for the tree(s). Booster trees can perform well in such situations by focusing and weighting those mistakes heavier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these efforts can be streamlined using GridSearch. Below, you can find code that tests different parameters using cross-validation for random forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best classifier: RandomForestClassifier(min_samples_leaf=5, n_estimators=20)\n",
      "Accuracy: 0.7985781990521327\n",
      "AUC: 0.693830876535688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# First we create a dictionary containing the parameters we want to test\n",
    "# We include the values we want to test as lists \n",
    "parameters = {'min_samples_leaf':[1,5],'max_depth':[None,10]}\n",
    "\n",
    "# Then, we bring together a classifier, the parameters, and set the number of folds for the CV\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators=20), parameters, cv=10)\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# The best predictor will be used for the prediction\n",
    "prediction = grid_search.predict(X_test)\n",
    "    \n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "print('Best classifier:',best_classifier)\n",
    "print('Accuracy:', accuracy_score(y_test,prediction))\n",
    "print('AUC:',roc_auc_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that having a minimum of 5 samples per leaf, and a maximum depth of 10 are preferable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all our models, we can calculate the feature importance. This is the (average) reduction in Gini impurity across all trees.\n",
    "\n",
    "Feature importance can be an important way of interpreting your results. It's also very interesting to compare this across different methods and understand how different algorithms value different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable tenure 0.16727768165830217\n",
      "Variable MonthlyCharges 0.17709360868438845\n",
      "Variable TotalCharges 0.19947377470287506\n",
      "Variable InternetService_Fiber optic 0.04238898476420349\n",
      "Variable PaymentMethod_Electronic check 0.03549385541802868\n"
     ]
    }
   ],
   "source": [
    "# Random forest - 5 most important features\n",
    "for c, column in enumerate(X_test.columns):\n",
    "    if rf.feature_importances_[c] in sorted(rf.feature_importances_)[-5:]:\n",
    "        print('Variable',column,rf.feature_importances_[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable tenure 0.2\n",
      "Variable MonthlyCharges 0.16\n",
      "Variable TotalCharges 0.28\n",
      "Variable InternetService_Fiber optic 0.04\n",
      "Variable Contract_One year 0.04\n",
      "Variable Contract_Two year 0.04\n",
      "Variable PaymentMethod_Electronic check 0.04\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost - 5 most important features\n",
    "for c, column in enumerate(X_test.columns):\n",
    "    if ada.feature_importances_[c] in sorted(ada.feature_importances_)[-5:]:\n",
    "        print('Variable',column,ada.feature_importances_[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both random forests and AdaBoost have exactly the same variables driving their Gini impurity down. Mostly the length of tenure, monthly charges, total charges, being connected through fiber and the contract length.\n",
    "\n",
    "Having both methods value the same features can strengthen our recommendations made to the company."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
